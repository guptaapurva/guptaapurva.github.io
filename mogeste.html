<!DOCTYPE html> 
<html lang="en">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <title>Apurva Gupta | Mogeste</title>
	<link rel="icon" type="image/png" href="favicon.png" />

    <!-- Bootstrap -->
    <link href="css/bootstrap.min.css" rel="stylesheet">
	<link href="css/style.css" rel="stylesheet">
	<link rel="stylesheet" href="css/blueimp-gallery.min.css">
	
	<!-- Custom Fonts -->
    <link href="font-awesome-4.1.0/css/font-awesome.min.css" rel="stylesheet" type="text/css">

    <!-- HTML5 shim and Respond.js for IE8 support of HTML5 elements and media queries -->
    <!-- WARNING: Respond.js doesn't work if you view the page via file:// -->
    <!--[if lt IE 9]>
      <script src="https://oss.maxcdn.com/html5shiv/3.7.2/html5shiv.min.js"></script>
      <script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
    <![endif]-->
  </head>
  
  <body style="padding-top: 50px;">
    <nav class="navbar navbar-default navbar-fixed-top" role="navigation">
	  <div class="container">
		<!-- Brand and toggle get grouped for better mobile display -->
		<div class="navbar-header">
		  <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#bs-example-navbar-collapse-1">
			<span class="sr-only">Toggle navigation</span>
			<span class="icon-bar"></span>
			<span class="icon-bar"></span>
			<span class="icon-bar"></span>
		  </button>
		  <a class="navbar-brand" href="index.html">Apurva Gupta</a>
		</div>

		<!-- Collect the nav links, forms, and other content for toggling -->
		<div class="collapse navbar-collapse" id="bs-example-navbar-collapse-1">
			<form class="navbar-form navbar-right">
				<!-- <a href="mogeste.html" class="btn btn-default"><b><</b> Motion Gestures</a> -->
				<a href="ride.html" class="btn btn-default">Ride-n-Guide <b>></b></a>
			</form>
			<ul class="nav navbar-nav navbar-right">
				<li><a href="index.html#portfolio">Portfolio</a></li>
				<li><a href="index.html#resume">Resume</a></li>
				<li><a href="index.html#about">About</a></li>
			</ul>
		</div><!-- /.navbar-collapse -->
	  </div><!-- /.container-fluid -->
	</nav>
	
	<!-- The Bootstrap Image Gallery lightbox, should be a child element of the document body -->
	<div id="blueimp-gallery" class="blueimp-gallery blueimp-gallery-controls">
		<!-- The container for the modal slides -->
		<div class="slides"></div>
		<!-- Controls for the borderless lightbox -->
		<h3 class="title"></h3>
		<a class="prev">‹</a>
		<a class="next">›</a>
		<a class="close">×</a>
		<a class="play-pause"></a>
		<ol class="indicator"></ol>
		<!-- The modal dialog, which will be used to wrap the lightbox content -->
		<div class="modal fade">
			<div class="modal-dialog">
				<div class="modal-content">
					<div class="modal-header">
						<button type="button" class="close" aria-hidden="true">&times;</button>
						<h4 class="modal-title"></h4>
					</div>
					<div class="modal-body next"></div>
					<div class="modal-footer">
						<button type="button" class="btn btn-default pull-left prev">
							<i class="glyphicon glyphicon-chevron-left"></i>
							Previous
						</button>
						<button type="button" class="btn btn-primary next">
							Next
							<i class="glyphicon glyphicon-chevron-right"></i>
						</button>
					</div>
				</div>
			</div>
		</div>
	</div>
	
	<div class="jumbotron" style="padding: 0">
		<img src="img/projects/mogeste/cover.png" width="100%">
		<div class="container" style="padding: 15px">
			MS-HCI Project | Individual | User Research, Comparative Analysis, Concept design and Prototype, User Testing, Expert Evaluation
		</div>
	</div>
	
	<section class = "container" style="padding-top: 0px">
		<div class="row">
			<div class = "col-md-10">
				<h2>Mogeste</h2>
				<h3>Motion-Based Mobile/Wearable Experience prototyping</h3>
			</div>
		</div>
		
		<div class="row">
			<div class = "col-md-12">
				<p>Mogeste is a motion-based mobile prototyping tool for designers which leverages existing interface prototyping paradigm and allows its users to use motion gestures as an interaction modality for their applications. The tool supports most commercial wearable devices and uses the inertial sensor data to build gesture recognisers on the fly.  </br>
				</p>
				<p><b>My role:</b> This was an ongoing project at Ubicomp Lab, Georgia Tech. under the guidance of Prof. Gregory Abowd. My role was to understand the design space of motion gestures and embed the implemented motion-gesture prototyping piece into larger mobile experience design process. </p>
				<div class="row">
					<div class="col-md-6">
						<div class="videoWrapper">
							<center>
								<iframe src="https://www.youtube.com/embed/xSDe7HUhq_0" frameborder="0" webkitallowfullscreen mozallowfullscreen allowfullscreen></iframe>
							</center>
						</div>
					</div>
					<div class="col-md-6">
						<div class="videoWrapper">
							<center>
								<iframe src="https://www.youtube.com/embed/FkqE6ea_p9M" frameborder="0" webkitallowfullscreen mozallowfullscreen allowfullscreen></iframe>
							</center>
						</div>
					</div>
				</div>
			</div>
			
			<div class="clearfix"></div><br>
		  
			<div class = "col-md-12">
				<p>The need and motivation for a mobile/wearable experience prototyping tool supporting motion gesture prototyping came from the following understanding.</p>
				<table width="99%" border="0">
				  <tr>
				    <th width="33%" scope="col"><img src="img/projects/mogeste/icon 1.png" width="244" height="345" alt="Devices"></th>
				    <th width="32%" scope="col"><img src="img/projects/mogeste/icon 2.png" alt="no tool" width="255" height="265"></th>
				    <th width="35%" scope="col"><img src="img/projects/mogeste/icon 3.png" alt="mobile exp. design" width="350" height="293"></th>
			      </tr>
				  <tr>
				    <td><h5>Abundance of Commercial wearable devices </h5>
                    <p>There has been growing interest in commercial wearable devices like smart watches, bands, glass, etc. over the past few years. This has led to many explorations in novel interaction modalities for such devices. Due to the presence of inertial sensors on these devices, motion gestures have been used to enhance the experience with these devices. For example, flicking the wrist enables scroll on the watch and a gentle heads-up switched the glass screen on.</p>
                    <p>&nbsp;</p></td>
				    <td><h5>No tool to support motion gesture prototyping </h5>
                    <p> Building a robust motion gesture recogniser requires advanced machine learning expertise which majority of the design community doe not have. They rely heavily on developers and are at their mercy to propose their ideas. There is no tool which facilitates creativity and refocuses designers efforts back to design without worrying about computational overheads. </p>
                    <p>&nbsp;</p>
                    <p>&nbsp;</p></td>
				    <td><h5 dir="ltr">Motion Gesture is just a part of larger Mobile Experience Design</h5>
				    <p> Interaction modalities makes sense in the presence of a context or application. Thus, motion gesture prototyping is a mere part of designing a larger experience with the mobile/wearable devices. There is, thus, a need for a prototyping tool that supports designers processes beginning from user research to design to evaluation of their ideas</p>
				    <p>&nbsp;</p>
				    <p>&nbsp;</p>
				    <p>&nbsp;</p></td>
			      </tr>
			  </table>
				<p> If motion gestures were to become a common interaction modality, the underlying question was how to equip designers with tools that can support the motion gesture design process.</p>
				<div class="row"></div>
				<img src="img/projects/mogeste/motivation.png" alt="..." width="100%">
			</div>
			
			<div class="clearfix"></div><br>
			
			<div class = "col-md-12">
				<p> To answer the question and  validate the need for an intervention, an iterative user centered design process was followed to collect user requirements, understand motion gesture design space, evaluate the implemented prototype, extend the scope to larger mobile interface prototyping and conduct an expert evaluation of the UI elements.</p>
				<img src="img/projects/mogeste/process.jpg" alt="..." width="100%">
			</div>
			
			<div class="clearfix"></div><br>
			
			<div class = "col-md-12">
				<h4> Understanding the Motion gesture design Space  </h4>
				<p dir="ltr">Being new to the motion gesture design myself, it was difficult to wrap my head around different aspects of the design process. To better understand the process followed by designers while designing motion gestures, two studies were conducted with 5 industry professionals and 12 novices.</p>
			  <h5 dir="ltr"><strong id="docs-internal-guid-dfbe689a-b769-e5a9-fb3e-f5f755f04d38">User study</strong></h5>
			  <table width="100%" border="1">
			    <tr>
			      <th scope="col"><h5 dir="ltr"><strong id="docs-internal-guid-dfbe689a-b769-e5a9-fb3e-f5f755f04d">User study- Novices</strong></h5>
                  <p dir="ltr">An activity-based study was conducted 7 novices who were 2nd year MS-HCI students who were exposed to design process but not necessarily motion gesture design. During the design task, they were asked to design 3 motion gestures for 2 common tasks of placing a phone call and ending the call using a smartphone. The task was followed by a semi structure interview probing deeper into their design, prototyping and evaluation process.</p>
                  <h5 dir="ltr"><strong>Industry Professional</strong></h5>
                  <p>A semi structured interview was conducted with 5 industry professionals from a large software company who have developed motion gestures for commercial wearable devices. The participants included both interaction designers and machine learning experts. The study lasted for 1 hour (avg.). </p>
                  <p dir="ltr">&nbsp;</p></th>
			      <th scope="col"><img src="img/projects/mogeste/study 1.png" width="422" height="208" alt="User study"></th>
		        </tr>
		      </table>
			  <h5 dir="ltr"><strong id="docs-internal-guid-dfbe689a-b781-8ff8-e133-746bf2ba6864">Using the grounded theory, the data from 12 participants was open coded and the themes emerged around the gesture design, implementation and stakeholder involvement in the process.</strong></h5>
		    <strong id="docs-internal-guid-dfbe689a-b769-e5a9-fb3e-f5f755f04d38">With the help of the themes and existing literature on prototyping tools, we identified 14 critical dimensions along which a gesture prototyping tool can be evaluated. These dimensions represent a design space that is useful for describing, evaluating, and generating motion gesture prototyping tools. To demonstrate the coverage of the design space, we also classified existing systems reviewed in the related work based on the design space placing the earlier version of Mogeste alongside the dimensions.</strong></div>
			
			<div class = "col-md-12">
				<h4 dir="ltr"><strong id="docs-internal-guid-dfbe689a-b770-d63a-4f1e-7fdbf622667d">User Testing</strong></h4>
				<p dir="ltr"><strong id="docs-internal-guid-dfbe689a-b770-d63a-4f1e-7fdbf622667d">After identifying the design space, we wanted to evaluate the already implemented tool against the dimensions and also for it's usability. With that goal in mind, we conducted a user testing with the same 7 novices and asked them to prototype the 6 gestures they had designed in the design task using the implemented tool. They were given a walk through of the tool prior to the tool use and asked a few questions as a follow-up to the study probing deeper about their experience, likes and dislikes with the tool. </strong></p>
				<br>
			  <h4 dir="ltr"><strong id="docs-internal-guid-dfbe689a-b770-d63a-4f1e-7fdbf622667d">The Tool</strong></h4>
				<p dir="ltr"><strong id="docs-internal-guid-dfbe689a-b770-d63a-4f1e-7fdbf622667d">The tool allows the user to record the intended gesture, runs background processes churning out a goodness score and allows the user to test the gesture if it's getting detected. Mogeste is designed to provide a 2 second time interval for the user to record the sample and the gesture is represented using the line chart showing sensor data along different axes. The video gives an idea of how the tool works.</strong><br>
				</p>
			  <p dir="ltr"><img src="img/projects/mogeste/Mogeste-AllScreens2.png" width="702" height="363" alt="mogeste 1.0"></p>
				<h4 dir="ltr"><strong id="docs-internal-guid-dfbe689a-b770-d63a-4f1e-7fdbf622667d">Participant Response</strong></h4>
				<table width="100%" border="1">
				  <tr>
				    <th width="56%" scope="col"><h5 dir="ltr"><strong id="docs-internal-guid-dfbe689a-b770-d63a-4f1e-7fdbf622667d3">The Good!</strong></h5>
                      <p dir="ltr"><strong id="docs-internal-guid-dfbe689a-b770-d63a-4f1e-7fdbf622667d3">We received a positive response from all our participants. They said the tool saves them time, is easy to learn and use and they don't have to code anything. They said it was cool, powerful and accurate. The most important insight was that our participants felt empowered after using the tool since all the participants mentioned a reliance over developers to help them build the gesture recogniser. They suggested that the tool is great for initial validation of ideas and rapid testing. </strong></p>
                      <br>
                      <p dir="ltr"><strong id="docs-internal-guid-dfbe689a-b770-d63a-4f1e-7fdbf622667d3">&ldquo;I could show developer that this gesture is doable.&rdquo;</strong></p>
                    <p dir="ltr"><strong id="docs-internal-guid-dfbe689a-b770-d63a-4f1e-7fdbf622667d3">&ldquo;I wouldn't have been able to do activity recognition myself. It took care of all that.&rdquo;</strong></p></th>
				    <th width="44%" scope="col"><h5 dir="ltr"><strong id="docs-internal-guid-dfbe689a-b770-d63a-4f1e-7fdbf622667d4">Opportunities</strong></h5>
                      <p dir="ltr"><strong id="docs-internal-guid-dfbe689a-b770-d63a-4f1e-7fdbf622667d4">There were certain things that the participants faced problems with. The recording mechanics of &nbsp;Gesture Start and end Position, Recording Duration and getting Recording Feedback was confusing to some users. </strong>                      </p>
                      <p dir="ltr"><strong id="docs-internal-guid-dfbe689a-b770-d63a-4f1e-7fdbf622667d4">They also did not understand the gesture playback after recording which was represented as a line chart. They said that although it seems useful, they do not understand what it does.</strong></p>
                      <p dir="ltr"><strong id="docs-internal-guid-dfbe689a-b770-d63a-4f1e-7fdbf622667d4">Another lingering question for some participants was &ldquo;How many samples are enough?&rdquo; They weren&rsquo;t sure when to provide more examples or how many of them were enough.</strong></p>
                    <p dir="ltr"><strong id="docs-internal-guid-dfbe689a-b770-d63a-4f1e-7fdbf622667d4">Some participants suggested embedding the tool within larger mobile experience design</strong></p></th>
			      </tr>
			  </table>
				<p dir="ltr">&nbsp;</p>
				<p dir="ltr"><strong>Based on these insights we moved forward and broadened the scope from motion gesture prototyping to mobile/wearable experience prototyping tool. </strong><strong id="docs-internal-guid-dfbe689a-b770-d63a-4f1e-7fdbf622667d">The earlier implemented version was a standalone motion gesture prototyping tool. But gesture design is just a part of larger mobile experience design. Thus, we shifted gears and embedded the implemented prototyping piece within a larger mobile interface prototyping tool that:</strong>				</p>
				<ol>
				  <li dir="ltr">
				    <p dir="ltr"><strong id="docs-internal-guid-dfbe689a-b770-d63a-4f1e-7fdbf622667d">Leverages interface prototyping paradigm of existing tools like Pop, marvel, pixate, etc. using motion gesture as an interaction Modality.</strong></p>
			      </li>
				  <li dir="ltr">
				    <p dir="ltr"><strong id="docs-internal-guid-dfbe689a-b770-d63a-4f1e-7fdbf622667d">Allows Motion gesture recording, testing and analysis.</strong></p>
			      </li>
			  </ol>
				<br>
				<h5 dir="ltr"><strong id="docs-internal-guid-dfbe689a-b770-d63a-4f1e-7fdbf622667d">Design </strong></h5>
				<p dir="ltr"><strong id="docs-internal-guid-dfbe689a-b770-d63a-4f1e-7fdbf622667d">The new mobile/wearable interface prototyping tool has two major pieces.</strong></p>
				<ol>
				  <li dir="ltr">
				    <p dir="ltr"><strong id="docs-internal-guid-dfbe689a-b770-d63a-4f1e-7fdbf622667d">Interface Prototyping<br>
				      Device 1: Running Core Mogeste Application + Video recording<br>
				      <br>
				      </strong></p>
			      </li>
				  <li dir="ltr">
				    <p dir="ltr"><strong id="docs-internal-guid-dfbe689a-b770-d63a-4f1e-7fdbf622667d">Motion Gesture Prototyping<br>
				      Device 2: Peripheral Device for Performing Gesture &nbsp;</strong></p>
			      </li>
			  </ol>
				<p dir="ltr"><strong id="docs-internal-guid-dfbe689a-b770-d63a-4f1e-7fdbf622667d">The concept was iteratively designed using paper prototypes and mockups. Finally, the UI was designed using Android Material design guidelines.</strong></p>
				<p dir="ltr"><strong id="docs-internal-guid-dfbe689a-b770-d63a-4f1e-7fdbf622667d">(Add IA)</strong></p>
				<p dir="ltr"><strong id="docs-internal-guid-dfbe689a-b770-d63a-4f1e-7fdbf622667d">(Add paper mockups photo)</strong></p>
			  <p dir="ltr"><strong id="docs-internal-guid-dfbe689a-b770-d63a-4f1e-7fdbf622667d">(Add video)</strong></p>
			</div>
			
			<div class = "col-md-12">
				<h4 dir="ltr"><strong id="docs-internal-guid-dfbe689a-b770-d63a-4f1e-7fdbf622667d2">EXPERT EVALUATION</strong></h4>
                <p dir="ltr"><strong id="docs-internal-guid-dfbe689a-b770-d63a-4f1e-7fdbf622667d2">After designing the interface a mid-fidelity prototype was built and tested by 5 HCI experts. The goal of the study was to evaluate the UI components of the interface and test if the user mental model would match the system model. The experts were asked to use the tool and evaluate it against mobile interface heuristics. Some of the screens from the prototype are shown here.</strong><br>
                </p>
                <h5 dir="ltr"><strong id="docs-internal-guid-dfbe689a-b770-d63a-4f1e-7fdbf622667d2">Recommendations</strong></h5>
                <table width="100%" border="1">
                  <tr>
                    <th width="50%" scope="col"><p dir="ltr"><strong id="docs-internal-guid-dfbe689a-b770-d63a-4f1e-7fdbf622667d5">Interface Prototyping Piece:</strong></p>
                    <p dir="ltr"><strong id="docs-internal-guid-dfbe689a-b770-d63a-4f1e-7fdbf622667d5">The experts found the tool consistent with the material design principles. They found the tool familiar with the existing flow of prototyping tools. It was easy for them to navigate and they felt when the tool would be functional it would be efficient.</strong></p></th>
                    <th width="50%" scope="col"><p dir="ltr"><strong id="docs-internal-guid-dfbe689a-b770-d63a-4f1e-7fdbf622667d6">Motion Gesture Prototyping Piece:</strong></p>
                    <p dir="ltr"><strong id="docs-internal-guid-dfbe689a-b770-d63a-4f1e-7fdbf622667d6">There were some concerns in the motion prototyping piece. The experts suggested having a better story telling around it to help the user understand the importance of samples. There should also be better handholding along this piece since this is not something that they have used before. Sensor playback was still difficult to understand despite adding the video of the gesture. There were also some feature suggestions around sample level comparison and supporting test-logs.</strong></p></th>
                  </tr>
                </table>
			</div>
			
			<div class = "col-md-12">
				<h4> Learnings and Future Direction </h4>
				<p>The major takeaway for the project was to understand the motion gesture design space and process. It is interesting how early inputs can trigger gesture search and enable better design decisions. To add to the tool, an everyday gesture library can be built which gives real-time feedback to the designer if the gesture would be confused with everyday action and also provide some common examples of the gestures to the designer to being their gesture search. I conducted an gesture elicitation study with 12 groups (of 2 each) each for wrist-worn and head-mounted devices wherein each group designed gestures for common tasks done on mobile devices. I hypothesize, that results from the study will impact the future design and feature the tool would support.</p>
			</div>

		</div>
			
	</section>
	

    <footer style="background-color: #f7f7f7; padding: 25px 0px">
        <div class="container" >
            <div class="row">
                <div class="col-sm-12">
                    <span class="copyright">Copyright &copy; Apurva Gupta 2016</span>
                </div>
            </div>
        </div>
    </footer>

	<!-- jQuery -->
    <script src="js/jquery.js"></script>
	
    <!-- jQuery (necessary for Bootstrap's JavaScript plugins) -->
    <!-- <script src="https://ajax.googleapis.com/ajax/libs/jquery/1.11.1/jquery.min.js"></script> -->
    <!-- Include all compiled plugins (below), or include individual files as needed -->
    <script src="js/bootstrap.min.js"></script>

	<!-- Filters -->
	<!-- <script type="text/javascript" src="http://ajax.googleapis.com/ajax/libs/jquery/1.10.2/jquery.min.js"></script> -->
	<script src="js/main.js"></script>
	<script src="js/isotope.min.js"></script>
	
	<script type="text/javascript" src="js/jquery.blueimp-gallery.min.js"></script>
  </body>
</html>