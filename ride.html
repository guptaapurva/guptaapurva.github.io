<div id='target'>
	<div class="row">
		<div class = "col-md-12">
			<center>
				<image src="img/projects/ride/cover.png" width="100%">
			</center>
		</div>
	</div>
	
    <div class = "container">
	<div class="row">
		<div class = "col-md-12">
			<h2>Ride-n-Guide</h2>
			<h3>Facilitating effective communication between ride leaders on group bike rides</h3>
		</div>
	</div>
	
	<div class="row">
	
		<div class = "col-md-12">
			<p>Ride-n-Guide is a communication system which enables ride leaders to better communicate with other ride leaders on the ride and pull navigational information from the system. The system enable an always on conference call between the ride leaders. The microphone is mute by defaut and can be switched on when speaking. The GPS directions can be pulled by switching it ON. Two input models viz button-based and gesture-based were designed and evaluated. It was found that sers found the button-based system to be better and felt more confident while using it.</p>
		</div>
		
		<div class = "col-xs-12 col-md-6">
		  <h4>Problem Space </h4>
			<p dir="ltr">On social group rides, ride leaders provide an analog support infrastructure while they&rsquo;re on the road. These volunteers serve multiple functions: they scout the route, shepherd riders through foreign neighborhoods, and administer emergency health and mechanical aid. These functions require that the leaders space themselves throughout the long train of riders. This helps them to maintain visual and/or auditory contact with the full group, but it strips them of the means to communicate with one another during the ride.</p>
			<p>We propose to build a system that will assist leaders in guiding group participants through a safe and enjoyable ride. This system will permit voice communication among leaders at distances outside auditory range through a hands-free interface. The system will take special note of the unique safety concerns of the leaders&rsquo; contexts, ensuring that it does not significantly diminish their ability to respond to their environment.</p>
			<p>&nbsp;</p></div>
     
      
	  <div class = "col-xs-12 col-md-6"> 
	    <h4>Design Alternatives</h4>
		  <p>We conceptualised 3 design alternatives.</p>
		  <hr />
		  <table border="0" cellpadding="10">
		    <tr>
		      <td><strong>Push to talk</strong></td>
		      <td><strong>Augmented vision</strong></td>
		      <td><strong>Wearable Gestures</strong></td>
	        </tr>
		    <tr>
		      <td> • A bone conduction earpiece<br />
• A push-to-talk button mounted near the brakes<br />
• The button opens a voice channel to all leaders</td>
		      <td> • A headpiece permitting partial-FOV A.R.<br />
• Local &amp; global GPS overlays<br />
• Virtual markers for obstacles, points of interest<br />
• Handlebar controls: switch views, drop marker</td>
		      <td> • A wrist-mounted watch with HD screen<br />
• Input via hand gesture detection<br />
• Local GPS routing with virtual markers<br />
• Pairs with smartphone for more detailed view</td>
	        </tr>
	    </table>
		  <p>&nbsp;</p>
	  </div>
	  
      <div class = "col-xs-12 col-md-6">
       <h4>Final Design and Prototype</h4>
		  <table>
		  
		    <tr>
		      <td colspan="2"><p dir="ltr">For the final design we combined the pust-to-talk and gesture based alternatives and designed two input variations for our system which creates a universal conference bridge for all ride leaders to communicate with each other</p></td>
	        </tr>
		    <tr>
		      <td><p ><strong>Input 1: Button-Based</strong></p></td>
		      <td><p><strong>Input 2: Wearable Gestures</strong></p></td>
	        </tr>
		    <tr>
		      <td><p><em>Prototype Input: </em><br />
		        PTT button (green) - Turns microphone ON/OFF with LED feedback</p>
		        <p dir="ltr">GPS button (yellow) - Requests navigational directions</p>
		        <p dir="ltr"><em>Prototype Components:</em> &nbsp;Arduino circuit with two functional physical buttons connected to the PTT experimenter&rsquo;s (wizard) computer, relaying information on button press.</p>
		        <p ><em>Location:</em> Buttons strapped to handlebars of a stationary bicycle.</p>
		        <p><em>Output:</em> Pretense of PTT mute/unmute on bone conduction headset</p></td>
		      <td><p><em>Prototype Input: <br />
		      </em>PTT gesture - Turns microphone ON/OFF. Feedback through vibration (2 pulses on, 1 pulse off), and on watch face.</p>
		        <p >GPS gesture - Requests navigational directions.</p>
		        <p ><em>Prototype Components:</em> ;Pebble watch, application relaying information on gesture to PTT experimenter&rsquo;s (wizard) computer </p>
		        <p ><em>Location</em>: Watch worn by the user.</p>
		        <p dir="ltr"><em>Output:</em> Pretense of PTT mute/unmute on bone conduction headset</p></td>
	        </tr>
	    </table>
		  <p>&nbsp;</p>
		</div>

          
          <div class="clearfix"></div>
          
          <div class = "col-xs-12 col-md-6">
       <h4>User Evaluation and Findings</h4>
       <p>Due to IRB constraints, evaluation was conducted on a stationary bike using a Wizard of Oz method and simulated virtual ride.	Two	input conditions were tested for switching the microphone from Mute to Unmute or accessing GPS information. The conditions were:<br />
         ~ Button-based system having two buttons one each for microphone and GPS. Feedback through LED<br />
~ Gesture-based system with two gestures one each for microphone and GPS. Feedback through vibrations and visual display on the watch.</p>
       <p>Findings:</p>
       <table>
               
        
         <tr>
           <td><p dir="ltr"><strong id="docs-internal-guid-86d3288e-66ef-ca25-f02d-3fddb5c0b4fe">Gesture Condition</strong></p></td>
           <td><p dir="ltr"><strong id="docs-internal-guid-86d3288e-66ef-ca25-f02d-3fddb5c0b4fe">Button Condition</strong></p></td>
         </tr>
         <tr>
           <td><ul>
             <li dir="ltr">
               <p dir="ltr">Input success was ambiguous</p>
             </li>
             <li dir="ltr">
               <p dir="ltr">Cognitively overwhelming</p>
             </li>
             <li dir="ltr">
               <p dir="ltr">Hand unable to perform essential tasks</p>
             </li>
             <li dir="ltr">
               <p dir="ltr">Learning gestures more difficult than expected</p>
             </li>
           </ul></td>
           <td><ul>
             <li dir="ltr">
               <p dir="ltr">Good tactile feedback</p>
             </li>
             <li dir="ltr">
               <p dir="ltr">Mimics familiar gear shift action</p>
             </li>
             <li dir="ltr">
               <p dir="ltr">Allows manipulation with thumb</p>
             </li>
             <li dir="ltr">
               <p dir="ltr">Users prefer right side, regardless of handedness</p>
             </li>
           </ul></td>
         </tr>
       </table>
       <p>&nbsp;</p>
       <p>&nbsp;</p>
	  </div>
        
        <div class = "col-xs-12 col-md-6">
       <h4>Proposed Changes</h4>
		  <p>~ Detachable clip-on buttons which can be put wherever user is most comfortable in using them.</p>
		  <p dir="ltr">~ Single side bone-conduction headset preferable on the left ear.</p>
		  <p>~ Visual Output: Using a visual display of GPS information either by mounting the smartphones of the user to the handlebar or attaching an external small screen.</p>
		  <p>&nbsp;</p>
        </div>
          
          <div class = "col-xs-12 col-md-6">
       <h4>Insights</h4>
		  <p>Firstly, the project helped to understand the user centered design process. The idea behind the project was to follow the process and design and evaluate the system. Failure at any step meant improvement in the overall design. Secondly, the project caters to a very specific user segment and has economic potential. The users have been facing the problem and are open to adopting low cost interventions.</p>
		</div>
		
		
	</div>
</div>
</div>